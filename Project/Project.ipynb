{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "As the world becomes more connected with platforms online, it is important to analyze trends as they occur in real time to understand their scope and features. This project analyzes the elements used in detecting disasters using twitter data and supervised machine learning to setermine if the event is true or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "The first step in the Data Analysis Process is data extration. Here, the data will be extracted from a dataset and the different variables will be examined.\n",
    "In this case, the data comes from a .csv dataset found on the kaggle.com website and has already been modified to contain a target outcome. To first understand the description of the data, it first needs to be imported into a pandas DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # Import the pandas library as pd.\n",
    "# Import the csv dataset file, and assign it to a DataFrame object called 'dataset' for further processing.\n",
    "dataset = pd.read_csv(\"nlptrain.csv\", sep = \",\") # Use a comma as the delimiter inside of the dataset.\n",
    "dataset # Print the contents of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been extracted and imported into a pandas DataFrame object, we can see that there are a total of five variables available, and this includes id, keyword, location, text, and target. The id column is used to provide each record with a unique primary key/identifier. The keyword column shows the keyword extracted from the text column which resembles a disaster. The location column describes the location of where the tweet or disaster occured, and the target variable is the dependent variable of this dataset which classifies whether the tweet contains a disaster or not. Here, 1 in this field represents true and 0 represents false. \n",
    "\n",
    "Below, the datatypes of each variable are shown, and this is important to understand, because our features need to will be required to be a number, since we are building mathematical models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           int64\n",
       "keyword     object\n",
       "location    object\n",
       "text        object\n",
       "target       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "The next step in the Data Analysis Process is to prepare the data. Here, we will need to transform the tweets into vectors of word frequency. After this stage, feature selection may be used, and in this case it will be used further below so that the results between the two methods can be compared.\n",
    "\n",
    "To begin, the CountVectorizer class must be imported into the program from the sklearn library to use as an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>007npen6lg</th>\n",
       "      <th>00cy9vxeff</th>\n",
       "      <th>00end</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>0215</th>\n",
       "      <th>...</th>\n",
       "      <th>Ã»Ã²</th>\n",
       "      <th>Ã»Ã²800000</th>\n",
       "      <th>Ã»Ã²the</th>\n",
       "      <th>Ã»Ã²Ã¥Ãªcnbc</th>\n",
       "      <th>Ã»Ã³</th>\n",
       "      <th>Ã»Ã³her</th>\n",
       "      <th>Ã»Ã³kody</th>\n",
       "      <th>Ã»Ã³negligence</th>\n",
       "      <th>Ã»Ã³tech</th>\n",
       "      <th>Ã»Ã³we</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 21363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  0000  007npen6lg  00cy9vxeff  00end  00pm  01  02  0215  ...  \\\n",
       "0      0    0     0           0           0      0     0   0   0     0  ...   \n",
       "1      0    0     0           0           0      0     0   0   0     0  ...   \n",
       "2      0    0     0           0           0      0     0   0   0     0  ...   \n",
       "3      0    1     0           0           0      0     0   0   0     0  ...   \n",
       "4      0    0     0           0           0      0     0   0   0     0  ...   \n",
       "...   ..  ...   ...         ...         ...    ...   ...  ..  ..   ...  ...   \n",
       "7608   0    0     0           0           0      0     0   0   0     0  ...   \n",
       "7609   0    0     0           0           0      0     0   0   0     0  ...   \n",
       "7610   0    0     0           0           0      0     0   1   0     0  ...   \n",
       "7611   0    0     0           0           0      0     0   0   0     0  ...   \n",
       "7612   0    0     0           0           0      0     0   0   0     0  ...   \n",
       "\n",
       "      Ã»Ã²  Ã»Ã²800000  Ã»Ã²the  Ã»Ã²Ã¥Ãªcnbc  Ã»Ã³  Ã»Ã³her  Ã»Ã³kody  Ã»Ã³negligence  Ã»Ã³tech  \\\n",
       "0      0         0      0         0   0      0       0             0       0   \n",
       "1      0         0      0         0   0      0       0             0       0   \n",
       "2      0         0      0         0   0      0       0             0       0   \n",
       "3      0         0      0         0   0      0       0             0       0   \n",
       "4      0         0      0         0   0      0       0             0       0   \n",
       "...   ..       ...    ...       ...  ..    ...     ...           ...     ...   \n",
       "7608   0         0      0         0   0      0       0             0       0   \n",
       "7609   0         0      0         0   0      0       0             0       0   \n",
       "7610   0         0      0         0   0      0       0             0       0   \n",
       "7611   0         0      0         0   0      0       0             0       0   \n",
       "7612   0         0      0         0   0      0       0             0       0   \n",
       "\n",
       "      Ã»Ã³we  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "...    ...  \n",
       "7608     0  \n",
       "7609     0  \n",
       "7610     0  \n",
       "7611     0  \n",
       "7612     0  \n",
       "\n",
       "[7613 rows x 21363 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # Import the CountVectorizer class for feature extraction.\n",
    "\n",
    "# Create a CountVectorizer object.\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Transform the words in the 'text' column into vectors of word frequency, and fit the data along the x axis.\n",
    "X = vectorizer.fit_transform(dataset['text'])\n",
    "\n",
    "# Create another DataFrame object with using the extracted features above inside of a dense matrix.\n",
    "df_tf = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Assign extracted features DataFrame object to the variable x and the target variable in the dataset to variable y.\n",
    "x = df_tf\n",
    "y = dataset[\"target\"]\n",
    "\n",
    "# Print the DataFrame object's contents containing the extracted features and their word frequency.\n",
    "df_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the Data\n",
    "The next step in the Data Analysis Process is to split the data into separate training and testing data sets. In this case, the traditional/conventional approach is used first by relying on the train_test_split function found in the sklearn library. Here, the data is split into two pieces by passing in the created x and y variables above. 80% of the original dataset will be used for training data, and 20% will be used for testing data. Furthermore, the results of this function are also assigned to the x and y variables used in these separate data sets.\n",
    "\n",
    "In a later section, the cross validation method will be used to split and train the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Import the sklearn library and the train_test_split function to split the data into two parts.\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=123) # Split the data at a random state to prevent overfitting and having a based outcome, and use 20% of the dataset as testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I printed the counts of the data inside of each set to verify that the contents of the target outcome variable is roughly stratified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total target counts\n",
      "\n",
      "target counts in training Y:\n",
      " 0    3463\n",
      "1    2627\n",
      "Name: target, dtype: int64\n",
      "\n",
      "target counts testing Y:\n",
      " 0    879\n",
      "1    644\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify the target counts in the split datasets.\n",
    "print(\"Total target counts\")\n",
    "print(\"\\ntarget counts in training Y:\\n\",train_y.value_counts())\n",
    "print(\"\\ntarget counts testing Y:\\n\",test_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These counts of the target variable indicate that the sampling is roughly stratified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Using the Chi-Squared Test\n",
    "Although a bag of words was used to hold all of the extracted features from earlier above, it unfortunately contained a large amount of unnesseary variables that can lead to biased outcomes and overfitted models. Thankfully, we can also extract significant features in the dataset using the Chi-Squared test. Using this method of feature selection requires discrete predicter and outcome variables which are already included in our dataset.\n",
    "\n",
    "To begin, the sklearn library needs to be imported to use the chi2() function using only the training data. Here, the features with the significant number will be used as specified by the p value. Our attributes will contain our bag of words and also use this p value of <0.05, although sometimes 0.01 may be used instead. This is because this value is actually the f value used in statistics and means that the feature is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features: 1104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['00', '01', '04', ..., 'zionist', 'zone', 'Ã»Ã¯when'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the chi2() function and other relevant functions.\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.feature_selection import *\n",
    "\n",
    "# Compute the f value and p value of the chi-squared test between each attribute and the target variable.\n",
    "f_val, p_val = chi2(train_x, train_y) \n",
    "\n",
    "# Create a new pandas DataFrame object with the newly computed scores.\n",
    "df_scores = pd.DataFrame(zip(df_tf, f_val, p_val), columns=[\"feature\", \"chi2\", \"p\"])\n",
    "df_scores[\"chi2\"] = df_scores[\"chi2\"].round(2)\n",
    "df_scores[\"p\"] = df_scores[\"p\"].round(3)\n",
    "\n",
    "# Use features with p value < 0.05 (significant features).\n",
    "sel_ohe_cols = df_scores[df_scores[\"p\"]<0.05][\"feature\"].values\n",
    "print(\"\\nSelected features: %d\" % len(sel_ohe_cols))\n",
    "sel_ohe_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Different Predictive Models\n",
    "### 13 Nearest Neighbors\n",
    "The first type of predictive model that will be built is going to be using the 13 nearest neighbors. This type of lazy and instance-based learning will use the 13 closest training instances to predict the outcome of the target variable. To begin, the KNeighborsClassifier class must be imported from the sklean library. Then, an instance of this class must be created with the parameter n_neighbors=13 to specify the number of nearest neighbors to be used. Afterwards, the model is trained by fitting the training dataset variables, and then a predicted y variable is created using this training data. Finally, the performance of the model is calculated by importing the required accuracy_score, f1_score, precision_score, and recall_score functions from the sklearn library. These allow us to measure the performance of the model, and by combining the \"pred_y, test_y\" values we can compute f1 and other values.\n",
    "\n",
    "\n",
    "As one can see further below, the accuracy of this predicted model is almost at 65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without feature selection:\n",
      "f1:0.2988204456094365\n",
      "accuracy:0.6487196323046619\n",
      "precision:0.17701863354037267\n",
      "recall:0.957983193277311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier # Import the KNeighborsClassifier class.\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=13) # Create an object from the class by calling its constructor method with the specified number of neighbors to use.\n",
    "\n",
    "# Train the model by fitting the training dataset variables (x=independant, y=dependant).\n",
    "knn = knn.fit(train_x, train_y)\n",
    "# Create a predicted y variable for the model to test the model.\n",
    "knn_pred_y = knn.predict(test_x)\n",
    "\n",
    "# Evaluate the prediction results by importing the required libraries to show the statistics.\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Here we can evaluate the performance of the model and compare the results to other trained models.\n",
    "print(\"Results without feature selection:\")\n",
    "print(\"f1:\" + str(f1_score(knn_pred_y, test_y)))\n",
    "print(\"accuracy:\" + str(accuracy_score(knn_pred_y, test_y)))\n",
    "print(\"precision:\" + str(precision_score(knn_pred_y, test_y)))\n",
    "print(\"recall:\" + str(recall_score(knn_pred_y, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with feature selection:\n",
      "f1:0.4139590854392299\n",
      "accuracy:0.680236375574524\n",
      "precision:0.2670807453416149\n",
      "recall:0.9197860962566845\n"
     ]
    }
   ],
   "source": [
    "knn_fs = KNeighborsClassifier(n_neighbors=13)# Create a new KNeighborsClassifier object by calling its constructor method.\n",
    "\n",
    "# Train the model by fitting the training dataset variables (x=independant(using significant features), y=dependant).\n",
    "knn_fs = knn_fs.fit(train_x[sel_ohe_cols], train_y)\n",
    "# Create a predicted y variable (using selected significant features) for the model to test the model.\n",
    "knn_fs_pred_y = knn_fs.predict(test_x[sel_ohe_cols])\n",
    "\n",
    "# Evaluate the prediction results and show the statistics to evaluate the performance of the model and compare the results to other trained models.\n",
    "print(\"Results with feature selection:\")\n",
    "print(\"f1:\" + str(f1_score(knn_fs_pred_y, test_y)))\n",
    "print(\"accuracy:\" + str(accuracy_score(knn_fs_pred_y, test_y)))\n",
    "print(\"precision:\" + str(precision_score(knn_fs_pred_y, test_y)))\n",
    "print(\"recall:\" + str(recall_score(knn_fs_pred_y, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see the results that included feature selection, and these statistics indicate that feature selection increased all of the values except for recall of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "The second type of predictive model that will be built is going to be using a decision tree classifier. This type of modeling requires the outcome variable to be discrete and is predicted using other discrete attributes. As a result, all continuous attributes will need to be discrete, and thankfully this is not a problem in our dataset.\n",
    "\n",
    "To begin, the tree module from the sklearn library is imported to access the DecisionTreeClassifier class, then an instance of this class is created. Next, this object will be used with the training variables and a model will be created. Finally, it will be evaluated by viewing its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without feature selection:\n",
      "f1:0.7049180327868854\n",
      "accuracy:0.7636244254760342\n",
      "precision:0.6677018633540373\n",
      "recall:0.7465277777777778\n"
     ]
    }
   ],
   "source": [
    "# Import tree module from the sklean library.\n",
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier() # Create the DecisionTreeClassifier object by calling its constructor method.\n",
    "\n",
    "# Use the newly created clf object, and fit the training data along the x and y axis.\n",
    "dt = dt.fit(train_x, train_y)\n",
    "# Create a predicted y variable for the model to test the model.\n",
    "dt_pred_y = dt.predict(test_x)\n",
    "\n",
    "# Evaluate the prediction results and show the statistics to evaluate the performance of the model and compare the results to other trained models.\n",
    "print(\"Results without feature selection:\")\n",
    "print(\"f1:\" + str(f1_score(dt_pred_y, test_y)))\n",
    "print(\"accuracy:\" + str(accuracy_score(dt_pred_y, test_y)))\n",
    "print(\"precision:\" + str(precision_score(dt_pred_y, test_y)))\n",
    "print(\"recall:\" + str(recall_score(dt_pred_y, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with feature selection:\n",
      "f1:0.6810344827586207\n",
      "accuracy:0.7570584372948129\n",
      "precision:0.6133540372670807\n",
      "recall:0.7655038759689923\n"
     ]
    }
   ],
   "source": [
    "dt_sf = tree.DecisionTreeClassifier()# Create a new DecisionTreeClassifier object by calling its constructor method.\n",
    "\n",
    "# Use the clf object, and fit the training data (using selected significant features) along the x and y axis.\n",
    "dt_sf = dt_sf.fit(train_x[sel_ohe_cols], train_y)\n",
    "# Create a predicted y variable (using selected significant features) for the model to test the model.\n",
    "dt_sf_pred_y = dt_sf.predict(test_x[sel_ohe_cols])\n",
    "\n",
    "# Evaluate the prediction results and show the statistics to evaluate the performance of the model and compare the results to other trained models.\n",
    "print(\"Results with feature selection:\")\n",
    "print(\"f1:\" + str(f1_score(dt_sf_pred_y, test_y)))\n",
    "print(\"accuracy:\" + str(accuracy_score(dt_sf_pred_y, test_y)))\n",
    "print(\"precision:\" + str(precision_score(dt_sf_pred_y, test_y)))\n",
    "print(\"recall:\" + str(recall_score(dt_sf_pred_y, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, feature selection actually decreased the f1, accuracy, and precision of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "The third type of predictive model that will be built is going to be using the Support Vector Machine. This type of modeling searches for the hyperplane that separates two classes with the maximum margin. It is known for being robust to high-dimensional data due to the kernel tricks that it provides. In this case we will use a linear hyperplane, however it also allows the parameter of polynomial-like equations to classify data points. In addition, it can also be used with different classifiers that use different parameters to \"tune\" the data to have better results.\n",
    "\n",
    "To begin, the LinearSVC class must be imported from the sklearn library. Then, an instance of this class will be created with a random state to prevent having an overfitted model and biased outcome. Next, the model is trained, and the performance of the model is evaluated and displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without feature selection:\n",
      "f1:0.7327731092436974\n",
      "accuracy:0.7912015758371634\n",
      "precision:0.6770186335403726\n",
      "recall:0.7985347985347986\n"
     ]
    }
   ],
   "source": [
    "# Import the LinearSVC class form the sklearn library.\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Create an object of the LinearSVC class using a random state to prevent having an overfitted model.\n",
    "svc = LinearSVC(random_state=123456)\n",
    "\n",
    "# Use the clf object, and fit the training data along the x and y axis.\n",
    "svc = svc.fit(train_x, train_y)\n",
    "# Create a predicted y variable for the model to allow us to test the model.\n",
    "svc_pred_y = svc.predict(test_x)\n",
    "\n",
    "# Evaluate the prediction results and show the statistics to evaluate the performance of the model and compare the results to other trained models.\n",
    "print(\"Results without feature selection:\")\n",
    "print (\"f1:\" + str(f1_score(svc_pred_y, test_y)))\n",
    "print (\"accuracy:\" + str(accuracy_score(svc_pred_y, test_y)))\n",
    "print (\"precision:\" + str(precision_score(svc_pred_y, test_y)))\n",
    "print (\"recall:\" + str(recall_score(svc_pred_y, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with feature selection:\n",
      "f1:0.7261698440207972\n",
      "accuracy:0.7925147734734077\n",
      "precision:0.6506211180124224\n",
      "recall:0.8215686274509804\n"
     ]
    }
   ],
   "source": [
    "# Create a new object of the LinearSVC class using a random state to prevent having an overfitted model.\n",
    "svc_sf = LinearSVC(random_state=123456)\n",
    "\n",
    "# Use the clf object, and fit the training data (with selected significant features) along the x and y axis.\n",
    "svc_sf = svc_sf.fit(train_x[sel_ohe_cols], train_y)\n",
    "# Create a predicted y variable (using selected significant features) for the model to allow us to test the model.\n",
    "svc_sf_pred_y = svc_sf.predict(test_x[sel_ohe_cols])\n",
    "\n",
    "# Evaluate the prediction results and show the statistics to evaluate the performance of the model and compare the results to other trained models.\n",
    "print(\"Results with feature selection:\")\n",
    "print (\"f1:\" + str(f1_score(svc_sf_pred_y, test_y)))\n",
    "print (\"accuracy:\" + str(accuracy_score(svc_sf_pred_y, test_y)))\n",
    "print (\"precision:\" + str(precision_score(svc_sf_pred_y, test_y)))\n",
    "print (\"recall:\" + str(recall_score(svc_sf_pred_y, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the results of both models have a very similar accuracy and f1 scores. Here, the model with selected features appears to have a higher accuracy and recall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "The fourth type of predictive model that will be built is going to be using the Naive Bayes modeling algorithm. This type of modeling uses the Bayes theorem and is naive because of the independence assumption. As a result, it may return incorrect probability estimates if the independence assumption is violated, but it does not affect classification as long as this violation is evenly distributed across classes.\n",
    "\n",
    "To begin, the MultinomialNB class must be imported from the sklearn library. Then, it an instance of it must be created. Thereafter, the model is trained, and finally the performance of the model is evaluated and displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without feature selection:\n",
      "f1:0.7526358475263585\n",
      "accuracy:0.7997373604727511\n",
      "precision:0.7204968944099379\n",
      "recall:0.7877758913412564\n"
     ]
    }
   ],
   "source": [
    "# we import MultinomialNB from sklearn.naive_bayes library\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create an object of the MultinomialNB class.\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Use the nb object, and fit the training data along the x and y axis.\n",
    "nb = nb.fit(train_x, train_y)\n",
    "# Create a predicted y variable for the model to allow us to test the model.\n",
    "nb_pred_y = nb.predict(test_x)\n",
    "\n",
    "# Evaluate the prediction results and show the statistics to evaluate the performance of the model and compare the results to other trained models.\n",
    "print(\"Results without feature selection:\")\n",
    "print (\"f1:\" + str(f1_score(nb_pred_y, test_y)))\n",
    "print (\"accuracy:\" + str(accuracy_score(nb_pred_y, test_y)))\n",
    "print (\"precision:\" + str(precision_score(nb_pred_y, test_y)))\n",
    "print (\"recall:\" + str(recall_score(nb_pred_y, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with feature selection:\n",
      "f1:0.7325581395348837\n",
      "accuracy:0.788575180564675\n",
      "precision:0.6847826086956522\n",
      "recall:0.7875\n"
     ]
    }
   ],
   "source": [
    "# Recreate an object of the MultinomialNB class.\n",
    "nb_sf = MultinomialNB()\n",
    "\n",
    "# Use the nb object, and fit the training data (with selected features) along the x and y axis.\n",
    "nb_sf = nb_sf.fit(train_x[sel_ohe_cols], train_y)\n",
    "# Create a predicted y variable for the model to allow us to test the model.\n",
    "nb_sf_pred_y = nb_sf.predict(test_x[sel_ohe_cols])\n",
    "\n",
    "# Evaluate the prediction results and show the statistics to evaluate the performance of the model and compare the results to other trained models.\n",
    "print(\"Results with feature selection:\")\n",
    "print (\"f1:\" + str(f1_score(nb_sf_pred_y, test_y)))\n",
    "print (\"accuracy:\" + str(accuracy_score(nb_sf_pred_y, test_y)))\n",
    "print (\"precision:\" + str(precision_score(nb_sf_pred_y, test_y)))\n",
    "print (\"recall:\" + str(recall_score(nb_sf_pred_y, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that the results of each model indicate that performance of the model without feature selection appear to be better, however we also need to understand that the model may be overfitted due to the number of variables used in the bag of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Here, I also split the data using cross_validate function found in the sklean library as well. In this instance, the model will be split into 5 partitions using the cv=5 parameter, x and y variables, and the KNeighborsClassifier object which will be described later. Each partition will be interchangeably used to train and test the model with a ratio of 4 to 1 (total of 5 partitions) for training and testing. The benefits of this technique allow the model to become more robust with its outcome due to minimizing overfitting and having a biased outcome. This is because each model is evaluated and created using different partitions of the dataset to find the one with the best performance outcome.\n",
    "\n",
    "In this case, this was only used with the 13 Nearest Neighbors classifier using feature selection, because this process took my computer over 2 hours to complete. As a result, I decided to leave this code here to prove that I have been able to apply the logic behind using these methods and focus more on demonstrating my learned skills by creating solid documentation for this project. Thank you for teaching the class about this wonderful technology. I greatly appreciate learning about all of this from you and your stress on the most important steps in the data analysis process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Using KNearestNeighbors and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict  # Import the required cross_val_predict function.\n",
    "y_pred = cross_val_predict(knn_fs, x, y, cv=5) # Split the data into 5 partitions and use the KNeighborsClassifier object/classification model with the x(bag of words using feature selection) and y(target) variable.\n",
    "y_pred # Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73      4342\n",
      "           1       0.93      0.02      0.03      3271\n",
      "\n",
      "    accuracy                           0.58      7613\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report # Import the required classification_report function.\n",
    "print(\"Classification Report\")\n",
    "cr = classification_report(y, y_pred) # Compare testing and training data.\n",
    "print(cr.split('macro avg')[0]) # Print the classification report for KNearestNeighbors using feature selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
